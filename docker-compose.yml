services:
  agentzero:
    build:
      context: ./agent-zero
      dockerfile: Dockerfile
    container_name: agentzero_${INSTANCE_ID}
    privileged: true
    volumes:
      - AgentZeroInstances:/a0
    ports:
      - "80:${WEB_UI_PORT}"                             # Expose web UI port
    networks:
      - agent_network                                   # Connect to shared agent_network
    env_file:
      - ./agent-zero/.env                               # Load environment variables from .env file
    depends_on:
      - ollama                                          # Ensure ollama starts first

  ollama:
    build:
      context: ./ollama # Path to your local Ollama Dockerfile directory
      dockerfile: Dockerfile  # Name of the Dockerfile 
    volumes:
      - ${LOCAL_OLLAMA_DIR}:/root/.ollama/  # Mount the local Ollama directory to the container
    networks:
      - agent_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: ["gpu"]
    env_file:
      - ./ollama/.env   

volumes:
  AgentZeroInstances:
    driver: local

networks:
  agent_network:
    driver: bridge