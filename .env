# [Local]
INSTANCE_ID=1  # Set an initial instance ID; this can be changed when running each instance
LOCAL_AGENT_DIR=~/Documents/agent-zero/instances  # Set the path to the local directory to sync with the container

# [ollama]
OLLAMA_PORT=11434 
OLLAMA_CHAT_MODEL=llama3.1 # Model for performing tasks
OLLAMA_EMBED_MODEL=nomic-embed-text # Model for orchestrating agents
OLLAMA_UTILITY_MODEL=llama3.2   
OLLAMA_HOST=ollama # Needs to be set to the docker-compose service name

# [agent-zero]
OLLAMA_BASE_URL=http://${OLLAMA_HOST}:${OLLAMA_PORT} # Linking the base URL for OLLAMA dynamically
API_KEY_GOOGLE=AIzaSyCfBEjeyhAHDpwR5Wn0eohLdzU8PlyUSCM # This is the API key for Google (Kasper) -> Find out how to create a tool for this
CHAT_MODEL_PROVIDER=ollama
CHAT_MODEL_NAME=${OLLAMA_CHAT_MODEL} # Dynamically setting of initialize.py
EMBEDDING_MODEL_PROVIDER=ollama
EMBEDDING_MODEL_NAME=${OLLAMA_EMBED_MODEL} # Dynamically setting of initialize.py
UTIL_MODEL_PROVIDER=ollama
UTILITY_MODEL_NAME=${OLLAMA_UTILITY_MODEL}
TOKENIZERS_PARALLELISM=true
PYDEVD_DISABLE_FILE_VALIDATION=1